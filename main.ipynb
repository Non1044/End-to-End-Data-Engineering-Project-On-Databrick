{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "685da45f-6324-4d1a-9b42-5e5b7c188e0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"pip install -r https://raw.githubusercontent.com/George-Michael-Dagogo/World_news_tutorial/main/requirements.txt\")\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "import pandas as pd\n",
    "from newspaper import Article, Config\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from datetime import date, timedelta\n",
    "\n",
    "def extract_transform_function():\n",
    "    today = date.today()\n",
    "    yesterday = today - timedelta(days = 1)\n",
    "    day_before_yesterday = today - timedelta(days = 2)\n",
    "    newsapi = NewsApiClient(api_key=os.environ[\"NEWSAPI_KEY\"])\n",
    "\n",
    "    top_headlines = newsapi.get_top_headlines(   \n",
    "                                            category='entertainment',\n",
    "                                            language='en',\n",
    "                                            page_size = 90,\n",
    "                                            page= 1)\n",
    "    \n",
    "    articles = top_headlines.get('articles',[])\n",
    "    init_df = pd.DataFrame(articles, columns = ['source','title','publishedAt','author','url'])\n",
    "    init_df['source'] = init_df['source'].apply(lambda x: x['name'] if pd.notna(x) and 'name' in x else None)\n",
    "    init_df['publishedAt'] = pd.to_datetime(init_df['publishedAt'])\n",
    "    filtered_df = init_df[(init_df['publishedAt'].dt.date == day_before_yesterday) | (init_df['publishedAt'].dt.date == yesterday)]\n",
    "    filtered_df.rename(columns={'publishedAt': 'date_posted'}, inplace=True)\n",
    "    df = filtered_df.copy()\n",
    "\n",
    "    def full_content(url):\n",
    "        user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'\n",
    "        config = Config()\n",
    "        config.browser_user_agent = user_agent\n",
    "        page = Article(url, config = config)\n",
    "\n",
    "        try:\n",
    "            page.download()\n",
    "            page.parse()\n",
    "            return page.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving content from {url}: {e}\")\n",
    "            return 'couldnt retrieve'\n",
    "\n",
    "    df['content'] = df['url'].apply(full_content)\n",
    "    df['content'] = df['content'].str.replace('\\n', ' ')\n",
    "    df = df[df['content'] != 'couldnt retrieve']\n",
    "\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "    def count_words_without_stopwords(text):\n",
    "        if isinstance(text, (str, bytes)):\n",
    "            words = nltk.word_tokenize(str(text))\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "            return len(filtered_words)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    df['word_count'] = df['content'].apply(count_words_without_stopwords)\n",
    "\n",
    "    nltk.download('vader_lexicon')\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def get_sentiment(row):\n",
    "        sentiment_scores = sid.polarity_scores(row)\n",
    "        compound_score = sentiment_scores['compound']\n",
    "        if compound_score >= 0.05:\n",
    "            sentiment = 'Positive'\n",
    "        elif compound_score <= -0.05:\n",
    "            sentiment = 'Negative'\n",
    "        else:\n",
    "            sentiment = 'Neutral'\n",
    "        return sentiment, compound_score\n",
    "    df[['sentiment', 'compound_score']] = df['content'].astype(str).apply(lambda x: pd.Series(get_sentiment(x)))\n",
    "    return df\n",
    "\n",
    "dataframe = extract_transform_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aa409ab-9284-4e8c-bd67-54959d92844b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  %sql\n",
    "# CREATE DATABASE IF NOT EXISTS the_news;\n",
    "# CREATE TABLE IF NOT EXISTS the_news.news_table (\n",
    "# source STRING,\n",
    "# title STRING,\n",
    "# date_posted DATE,\n",
    "# author STRING,\n",
    "# url STRING,\n",
    "# content STRING,\n",
    "# word_count INT,\n",
    "# sentiment STRING,\n",
    "# compound_score DOUBLE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a056bd9c-4344-4e92-902e-112b73971d81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType, DoubleType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CreateTableExample\").getOrCreate()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"source\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"date_posted\", DateType(), True), \n",
    "    StructField(\"author\", StringType(), True),\n",
    "    StructField(\"url\", StringType(), True),\n",
    "    StructField(\"content\", StringType(), True),\n",
    "    StructField(\"word_count\", IntegerType(), True),\n",
    "    StructField(\"sentiment\", StringType(), True),\n",
    "    StructField(\"compound_score\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "spark_df = spark.createDataFrame(dataframe, schema=schema)\n",
    "spark_df.write.mode('append').saveAsTable('the_news.news_table')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4919318874726780,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "main",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
